{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.models import vit_b_16\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing on cpu\n",
      "Loading dataset from Torch tensor file...\n",
      "Dataset loaded successfully.\n",
      "Test dataset loaded successfully.\n",
      "Train samples: 4320, Val samples: 1080, Test samples: 100\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Runing on {str(device)}\")\n",
    "\n",
    "# Define dataset paths\n",
    "torch_train_path = \"./animals90TrainDataset.pt\"\n",
    "torch_test_path = \"./animals90TestDataset.pt\"\n",
    "\n",
    "# Define class names\n",
    "class_names =  [\n",
    "    \"antelope\", \"badger\", \"bat\", \"bear\", \"bee\", \"beetle\", \"bison\", \"boar\", \"butterfly\",\n",
    "    \"cat\", \"caterpillar\", \"chimpanzee\", \"cockroach\", \"cow\", \"coyote\", \"crab\", \"crow\",\n",
    "    \"deer\", \"dog\", \"dolphin\", \"donkey\", \"dragonfly\", \"duck\", \"eagle\", \"elephant\",\n",
    "    \"flamingo\", \"fly\", \"fox\", \"goat\", \"goldfish\", \"goose\", \"gorilla\", \"grasshopper\",\n",
    "    \"hamster\", \"hare\", \"hedgehog\", \"hippopotamus\", \"hornbill\", \"horse\", \"hummingbird\",\n",
    "    \"hyena\", \"jellyfish\", \"kangaroo\", \"koala\", \"ladybugs\", \"leopard\", \"lion\", \"lizard\",\n",
    "    \"lobster\", \"mosquito\", \"moth\", \"mouse\", \"octopus\", \"okapi\", \"orangutan\", \"otter\",\n",
    "    \"owl\", \"ox\", \"oyster\", \"panda\", \"parrot\", \"pelecaniformes\", \"penguin\", \"pig\",\n",
    "    \"pigeon\", \"porcupine\", \"possum\", \"raccoon\", \"rat\", \"reindeer\", \"rhinoceros\",\n",
    "    \"sandpiper\", \"seahorse\", \"seal\", \"shark\", \"sheep\", \"snake\", \"sparrow\", \"squid\",\n",
    "    \"squirrel\", \"starfish\", \"swan\", \"tiger\", \"turkey\", \"turtle\", \"whale\", \"wolf\",\n",
    "    \"wombat\", \"woodpecker\", \"zebra\"\n",
    "]\n",
    "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load dataset from Torch tensor file\n",
    "print(\"Loading dataset from Torch tensor file...\")\n",
    "train_data = torch.load(torch_train_path)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "test_data = torch.load(torch_test_path)\n",
    "print(\"Test dataset loaded successfully.\")\n",
    "train_images, train_labels = train_data[\"images\"], train_data[\"labels\"]\n",
    "test_images, test_labels = test_data[\"images\"], test_data[\"labels\"]\n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = int(0.2 * len(train_dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/david/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /Users/david/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:04<00:00, 71.6MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ViT model and modify classifier\n",
    "model = vit_b_16(pretrained=True)\n",
    "num_features = model.heads.head.in_features\n",
    "model.heads.head = nn.Linear(num_features, len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)\n",
    "\n",
    "epochs = 10  # Increase as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_accuracy(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"\n",
    "    Plots the training/validation loss and accuracy curves in separate charts.\n",
    "    \"\"\"\n",
    "    # Plot loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 2.7673, Train Acc: 0.5843\n",
      "Val Loss: 1.1751, Val Acc: 0.8704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accs   = []\n",
    "val_losses   = []\n",
    "val_accs     = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images_batch, labels_batch in train_loader:\n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track training loss\n",
    "        running_loss += loss.item() * images_batch.size(0)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels_batch).sum().item()\n",
    "        total += labels_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images_batch, labels_batch in val_loader:\n",
    "            images_batch = images_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "\n",
    "            outputs = model(images_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            \n",
    "            # Track validation loss\n",
    "            val_running_loss += loss.item() * images_batch.size(0)\n",
    "            # Compute validation accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels_batch).sum().item()\n",
    "            val_total += labels_batch.size(0)\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    \n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accs.append(val_epoch_acc)\n",
    "    \n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss and Accuracy\n",
    "plot_loss_and_accuracy(train_losses, val_losses, train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images_batch, labels_batch in test_loader:\n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        \n",
    "        outputs = model(images_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        \n",
    "        test_loss += loss.item() * images_batch.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_correct += predicted.eq(labels_batch).sum().item()\n",
    "        test_total += labels_batch.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_acc = test_correct / test_total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
